\chapter{Summary and Outlook}\label{ch:sum}

\section{Summary}\label{sec:conclusion}
In this thesis, I developed an algorithm for computing large \ac{fft}s on a \ac{soc} platform, addressing the specific challenges of medical ultrasound imaging. The choice of platform, the Xilinx Versal VCK190, with its specialized AI accelerator processors, reflected the broader goal of advancing mobile, real-time imaging solutions. Existing \ac{fft} implementations, whether tailored for this chip or for \ac{fpga}s more broadly, were evaluated but found insufficient for the stringent real-time requirements of ultrasound imaging. This shortfall necessitated the development of a custom algorithm designed to leverage the chip's AI accelerators while maintaining compatibility with a mobile platform.\par
The proposed algorithm, built with scalability and efficiency in mind, incorporates a streaming layer in the \ac{pl} to maximize data throughput. Benchmarking revealed that while the AI accelerators were capable of handling the computational demands, the streaming layer accounted for approximately 80\% of the runtime, preventing the system from achieving full real-time performance. Nonetheless, these results underscore the potential for optimized hardware-software integration to meet the demands of high-performance imaging.\par
While the immediate application of this work lies in medical ultrasound imaging, the implications of enhancing Fourier transformation algorithms extend far beyond. As discussed in the introduction, efficient \ac{fft} computations are crucial in fields such as radar imaging and mobile communications, where rapid frequency-domain processing underpins critical applications. By demonstrating the feasibility of high-performance \ac{fft} computation on a constrained SoC platform, this study lays the groundwork for advancements across these domains.\par
Future research could focus on overcoming the identified bottlenecks by manually optimizing the streaming layer using Verilog or VHDL or exploring the trade-offs of reduced data precision. Additionally, given the rapid evolution of AI accelerator technology, alternative chip architectures could further unlock real-time performance and scalability. These pathways offer exciting opportunities not only for improving ultrasound imaging but also for enhancing computational techniques in related fields.\par
In conclusion, this work represents a significant step toward realizing the vision outlined in the beginning: portable, high-performance imaging systems capable of transforming both clinical and non-clinical applications. While challenges remain, the foundation established here highlights the potential for real-time, frequency-domain processing to redefine the capabilities of imaging technologies.

\section{Outlook}\label{sec:future}
The previous chapter demonstrated promising results for utilizing a large real-time \ac{fft}. However, as shown by these results, the threshold for a fully real-time capable design and implementation of 8,524 FFTs per seconds has not yet been achieved. One of the primary contributing factors is the data streaming within the \ac{pl}. Since this was not the main focus of this work, a potential first step in further optimization could be a deeper investigation of streaming methods specifically suited to this purpose. The \ac{pl} is similar to a standard \ac{fpga}, which raises the question of whether streaming methods used in network applications, which also heavily depend on \ac{fpga}s, could be adapted here. In high-capacity network backbones, data streaming rates in the hundred gigabyte per second range are achievable \cite{jankovic_high-capacity_2020}. In comparison, the real-time target for this project requires a streaming rate of approximately 29 gigabytes per second, assuming the use of 64-bit complex floating-point values.\par
Another promising avenue for exploration is the potential reduction of resolution of the used data. Lowering the resolution could not only improve the streaming efficiency of the \ac{pl} but also expand the design space for the AI Engines. The Xilinx intrinsic functions, for instance, support data types down to 8 bits, allowing multiple values to be processed simultaneously in vector registers \cite{henry_leveraging_2019}. This change could also alleviate some of the memory constraints during streaming within the AI Engine array. A thorough analysis of precision requirements would be essential to determine whether this approach would indeed be advantageous. Alternatively, precision adjustments could focus not on the working data itself but on the precomputed values, which could help mitigate memory constraints without significantly impacting overall precision.\par
The exploration of precision leads to a broader question: the analysis of the entire system and the effect of precision on subsequent stages in the image generation pipeline. This would involve application-level testing of the algorithm through repeated or continuous execution. Such an approach would address some limitations of the test pipeline used in this study, which primarily assessed runtime and correctness based on a single algorithmic execution.\par
Another direction for future research could be experimenting with different hardware. The algorithm presented here largely employs a target offloading approach, which might also benefit from application to other hardware platforms. Examining the potential of accelerators may offer additional advantages, especially considering that the current design utilizes AI Engines in an accelerator-like capacity. Furthermore, investigating larger ACAP devices, which offer not only increased computational resources but also expanded memory capacity, could be advantageous given that memory is a key limiting factor in this design.